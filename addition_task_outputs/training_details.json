{
  "batch_size": 64,
  "learning_rate": 0.0005,
  "num_epochs": 10,
  "gradient_accumulation_steps": 1,
  "warmup_ratio": 0.0,
  "weight_decay": 0.0,
  "max_grad_norm": 1.0,
  "num_hidden_layers": 4,
  "hidden_size": 128,
  "num_attention_heads": 4,
  "intermediate_size": 512,
  "vocab_size": 13,
  "training_time_seconds": 545.5031335353851,
  "training_time_minutes": 9.091718892256418,
  "gpu_info": {
    "device": "Tesla T4",
    "memory_gb": 15.828320256
  }
}